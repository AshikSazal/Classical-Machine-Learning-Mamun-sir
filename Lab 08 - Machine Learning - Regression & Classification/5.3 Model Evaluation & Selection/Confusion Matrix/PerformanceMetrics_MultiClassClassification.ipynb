{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=\"Cat\"\n",
    "D=\"Dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual Values\n",
    "y_true=[C,C,C,C,C,C,D,D,D,D]\n",
    "#Predicted Values\n",
    "y_pred=[C,C,C,C,D,D,D,D,D,C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "#PRINT THE CONFUSION MATRIX\n",
    "cm=confusion_matrix(y_true, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Cat       0.80      0.67      0.73         6\n",
      "        Dog       0.60      0.75      0.67         4\n",
      "\n",
      "avg / total       0.72      0.70      0.70        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PRINT THE CLASSIFICATION REPORT - PRECISION, RECALL\n",
    "cr=classification_report(y_true, y_pred,digits=2)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix : Performance Metrics MultiClass Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score,precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=\"Cat\"\n",
    "D=\"Dog\"\n",
    "F=\"Fox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual Values\n",
    "y_true=[C,C,C,C,C,C,D,D,D,D,D,D,D,D,D,D,F,F,F,F,F,F,F,F,F]\n",
    "#Predicted Values\n",
    "y_pred=[C,C,C,C,D,F,C,C,C,C,C,C,D,D,F,F,C,C,C,D,D,D,D,D,D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1 1]\n",
      " [6 2 2]\n",
      " [3 6 0]]\n"
     ]
    }
   ],
   "source": [
    "#PRINT THE CONFUSION MATRIX\n",
    "cm=metrics.confusion_matrix(y_true, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Cat      0.308     0.667     0.421         6\n",
      "        Dog      0.222     0.200     0.211        10\n",
      "        Fox      0.000     0.000     0.000         9\n",
      "\n",
      "avg / total      0.163     0.240     0.185        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PRINT THE CLASSIFICATION REPORT - PRECISION, RECALL\n",
    "cr=metrics.classification_report(y_true, y_pred,digits=3)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix : Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report,precision_score, recall_score,f1_score,precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=\"Spam\"\n",
    "M=\"Not Spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=[M,M,M,M,M,M,S,S,S,S]\n",
    "y_pred=[M,M,M,M,S,S,S,S,S,M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=\"Not Spam\"\n",
    "N=\"Spam\"\n",
    "y_true=[P,P,P,P,P,P,N,N,N,N]\n",
    "y_pred=[P,P,P,P,N,N,P,N,N,N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "#PRINT THE CONFUSION MATRIX\n",
    "cm=confusion_matrix(y_true, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Not Spam      0.800     0.667     0.727         6\n",
      "       Spam      0.600     0.750     0.667         4\n",
      "\n",
      "avg / total      0.720     0.700     0.703        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PRINT THE CLASSIFICATION REPORT - PRECISION, RECALL\n",
    "cr=classification_report(y_true, y_pred,digits=3)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix : Cancer or HIV or Codid or Fire Alarm or Stock  Crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix as cm, classification_report as cr, cohen_kappa_score as cks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=\"HIV Positive\" \n",
    "N=\"Hiv Negative\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=[P,P,P,P,P,P,N,N,N,N]\n",
    "y_pred=[P,P,P,P,N,N,P,N,N,N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "#PRINT THE CONFUSION MATRIX\n",
    "cm=cm(y_true, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "HIV Positive      0.800     0.667     0.727         6\n",
      "Hiv Negative      0.600     0.750     0.667         4\n",
      "\n",
      " avg / total      0.720     0.700     0.703        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PRINT THE CLASSIFICATION REPORT - PRECISION, RECALL\n",
    "cr=cr(y_true, y_pred,digits=3)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kappa : float\n",
    "\n",
    "ohenâ€™s kappa is a useful evaluation metric when dealing with imbalanced data.\n",
    "\n",
    "The kappa statistic, which is a number between -1 and 1. \n",
    "\n",
    "The maximum value means complete agreement; zero or lower means chance agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-3d33b1daa3e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0mcohen_kappa_score\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#The Kohen Kappa Score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'P' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  cohen_kappa_score as cks\n",
    "#The Kohen Kappa Score\n",
    "y_true = [P,P,P,N]\n",
    "y_pred = [P,P,P,P]\n",
    "cks=cks(y_true, y_pred)\n",
    "print(cks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Receiver operating characteristic (ROC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn.metrics.roc_curve\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([1, 1, 2, 2])\n",
    "scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "#y = [1, 1, 2, 2]\n",
    "#scores = [0.1, 0.4, 0.35, 0.8]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y, scores, pos_label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.5, 0.5, 1. ])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 1. , 1. ])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8 , 0.4 , 0.35, 0.1 ])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
